[Лекция 6](https://youtu.be/s9XNphD2VBE?si=24glzfk2O3XdUfmE)
Лиза в процессе
Есть 2 состояния.
Функция А обеспечивает лучшее значение policy, функция В - имеет меньшую среднеквадратичную оценку, поэтому предпочтём её в соответствии с задачей оптимизаций.
![[Pasted image 20240123183104.png]]
Когда говорим о Q-learning - пытаемся решить прокси-задачу: сначала оцениваем функцию Q, а затем используем её для оценки качества действий во всех состояниях.
Но лучшая Q-функция иногда является неоптимальной.
![[Pasted image 20240123183208.png]]
Бывают разные стратегии
![[Pasted image 20240123184052.png]]
Детерминистические - Q-learning - определяются текущим состоянием
Стохастический - более общий (включает в себя детерминистический) - если делать стохастическую стратегию, то можно сойтись к детерминистической.
В каких ситуациях стохастическая политика лучше детерминистической?
Когда необходимо, чтобы оппонент 

Что делать, если действие произвольное число от нуля до единицы?
Как предсказывать вероятность для этого случая?
Максимизация вероятностного распределения на действие, чтобы мат ожидание и награда были наибольшими.
Есть 2 сценария:
![[Pasted image 20240123190757.png]]
Хотим максимизировать нашу награду по всем возможным траекториям
![[Pasted image 20240123190944.png]]


