[3-я лекция](https://youtu.be/aGsLzQla3nk?si=ImcSphYejsIy3Eou)

![[Pasted image 20240121225024.png]]
![[Pasted image 20240121205237.png]]
![[Pasted image 20240121205251.png]]
![[Pasted image 20240121205303.png]]

[[Грокаем_глубокое_обучение_с_подкреплением_NdMAJD.pdf | Из книжки]] со страницы 206, про SARSA:
![[Pasted image 20240123075331.png]]
![[Pasted image 20240121200346.png]]
![[Pasted image 20240121200321.png]]
Код агента SARSA:
![[Pasted image 20240123075923.png]]
![[Pasted image 20240123075957.png]]
![[Pasted image 20240123080030.png]]
![[Pasted image 20240123080109.png]]
Уравнения:
![[Pasted image 20240123080227.png]]
по EV-SARSA есть только этот слайд из лекции, возможно кто-то пояснит, в чем разница (вижу только что максимум заменен на матожидание (по сравнению с Q-learning), но для чего?):
![[Pasted image 20240121205251.png]]
Хотя в этой [[BartoSutton.pdf| книжке]] на странице 133, есть про EV-SARSA (надо бы разобрать что тут написано):
![[Pasted image 20240123225838.png]]
![[Pasted image 20240123225903.png]]
![[Pasted image 20240123225927.png]]

Про Q-learning (и on-policy, off-policy) уже есть в [[4. Between them. Monte Carlo vs TD update questions. Q-leaning algorithm#Q-leaning algorithm| 4-м вопросе]]

DQN с 296-й страницы:
![[Pasted image 20240121201318.png]]
еще буду разбираться....
.
.
