
1. **BoW, TF-iDF:**
    
    - BoW: BoW represents a document as a vector of word frequencies, ignoring word order. It's widely used in text classification.
    - TF-IDF: TF-IDF assigns weights to words based on their frequency in a document relative to the entire corpus, helping capture term importance.
2. **Word Embeddings (Word2Vec - CBOW, Skip-gram, Negative Sampling):**
    
    - Word Embeddings: Represent words as continuous vectors to capture semantic relationships.
    - CBOW: Predict a target word from its context.
    - Skip-gram: Predict context words from a target word.
    - Negative Sampling: Efficiently train Word2Vec models by sampling negative examples.
3. **CNNs in Text Processing:**
    
    - CNNs are used for text processing by applying filters over word embeddings to capture local patterns, useful for tasks like sentiment analysis.
4. **Seq2seq, Encoder-Decoder Models:**
    
    - Seq2Seq models consist of encoder and decoder components, often used in machine translation. The encoder processes input sequences, and the decoder generates output sequences.
5. **Attention Mechanism (Bahdanau et al.):**
    
    - Attention mechanisms improve Seq2Seq models by allowing the decoder to focus on specific parts of the input sequence, enhancing translation accuracy.
6. **Machine Translation, Quality Metrics:**
    
    - Machine Translation translates text from one language to another. Quality metrics include BLEU score, METEOR, and TER, evaluating translation performance.
7. **Unsupervised Translation Approach:**
    
    - Unsupervised translation doesn't require parallel corpora; it leverages monolingual data to learn translation without explicit translation pairs.
8. **Transformer Architecture, Self-Attention Mechanism:**
    
    - Transformers use self-attention mechanisms to weigh input sequence elements differently. This architecture revolutionized NLP tasks due to its parallelization capabilities.
9. **Transformer Architecture Details (Blocks Structure, Layer Norm, Training Procedure):**
    
    - Transformers consist of encoder and decoder blocks, each containing self-attention layers and feedforward networks. Layer normalization is applied, and training involves AdamW, LR scheduling, and label smoothing.
10. **BERT Pretraining, MLM, NSP Objectives:**
    
    - BERT pretraining involves Masked Language Modeling (MLM) and Next Sentence Prediction (NSP) objectives to learn contextualized word representations.
11. **BERT Finetuning, Transfer Learning Paradigm:**
    
    - BERT is finetuned for specific tasks after pretraining, showcasing the power of transfer learning in NLP.
12. **Discriminative Transformer Models (ROBERTA, ELECTRA, ALBERT):**
    
    - Discriminative models like ROBERTA, ELECTRA, and ALBERT modify transformer architectures for improved performance, efficiency, or training strategies.
13. **Question-Answering Systems:**
    
    - Question-answering systems use NLP to comprehend and respond to user queries, often employing models like BERT for contextual understanding.
14. **Self-Critical Sequence Training (SCST, RL-Related Approach in NLP):**
    
    - SCST is a reinforcement learning-related approach used in NLP for sequence generation tasks, optimizing model outputs based on a reward function.
15. **Neural Language Modeling, Quality Metrics:**
    
    - Neural language modeling predicts the probability of a sequence of words. Quality metrics include perplexity and BLEU score for evaluation.
16. **Transfer Learning Paradigm (T5, Instruction-Tuning - T0):**
    
    - T5 and instruction-tuning (T0) are examples of transfer learning paradigms in NLP, showcasing the ability to leverage pretrained models for various tasks.
17. **Generative Pretraining, Large Language Models, Basic LLM Adaptation:**
    
    - Generative pretraining involves training large language models (LLMs). Basic LLM adaptation includes zero-shot and few-shot prompting to generate desired outputs.
18. **Transfer Learning with LLMs, Finetuning Strategies:**
    
    - Transfer learning with LLMs involves finetuning pretrained models for specific tasks, using strategies like full finetuning, p-tuning, and adapters.
19. **Learning from Human Feedback for LLMs, ChatGPT Alignment (RLHF):**
    
    - Learning from human feedback for LLMs involves improving models based on user interactions. ChatGPT alignment, like RLHF (Reinforcement Learning from Human Feedback), refines models through reinforcement learning.