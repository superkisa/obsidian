**Corpus** - a set of all texts available at the training stage
**[Token](https://huggingface.co/docs/transformers/v4.36.1/en/glossary#token)** - is a smallest piece of information that cannot be split further / a part of a sentence, usually a word, but can also be a subword (non-common words are often split in subwords) or a punctuation symbol (элементарная единица текста, которую модель рассматривает в процессе обработки. Токены могут представлять собой отдельные слова, подслова (например, n-граммы или морфемы), символы или другие лингвистические элементы, в зависимости от выбранного уровня разбиения текста).
**[Tokenization](https://huggingface.co/docs/transformers/tokenizer_summary)** - extracting tokens from corpus of texts