[Лекция L11](https://www.youtube.com/watch?v=UIoMclQuSG8&list=PLH5AUD0BdzX7p017wqAN85gjARtrk73Wa&index=37)
Несколько форматов
Обучают их с помощью кросс-энтропии
![[Pasted image 20240118141628.png]]
Происходит метаобучение - обучение нескольких задач.
Используя эту форму для обучения множества задач одновременно.
Метаобучение - процедура, при которой различные задачи помогают друг другу, потому что у них есть некоторая базовая схожая информация, которую они используют. И как только модель подвергается воздействию обеих этих задач своего рода первая задача заставляет модель усвоить некоторые знания, которые были бы полезны для второй задачи. При этом извлечь уроки из второго задания было бы не столь просто, как извлечь их из первого.

Например, если вы тренируете машинный перевод и в тоже время вы тренируете некоторую классификацию на другом наборе данных и эта классификация содержит несколько иностранных слов, то вспомогательная задача перевода поможет задаче классификации лучше справиться с иностранными словами, так как задачи классификации недостаточно для того, чтобы выучить иностранные слова сами по себе.

По утверждению авторов статьи, такое построение на естественном языке помогает модели обобщать одну задачу с другой с помощью инструкций на естественном языке.
Таким образом, данные инструкции помогают программисту лучше понять свойства каждой задачи.
[Лекция L12](https://www.youtube.com/watch?v=7hud9GQIOP0&list=PLH5AUD0BdzX7p017wqAN85gjARtrk73Wa&index=38)

---

# Про Т0

>[!info]- кратко из чата по [статье](https://arxiv.org/abs/2110.08207)
> Статья под названием "Multitask Prompted Training Enables Zero-Shot Task Generalization" исследует возможность создания моделей машинного обучения, которые могут обобщать и выполнять задания, на которых они не обучались (так называемый zero-shot). В работе рассматривается гипотеза о том, что такое обобщение может быть результатом многозадачного обучения в процессе предварительного обучения языковых моделей.
>Авторы разработали систему, которая позволяет легко преобразовывать любые задачи обработки естественного языка в форму, удобную для чтения человеком, и использовали её для создания набора данных с разнообразными формулировками. Затем они дообучили предварительно обученную модель кодировщика-декодера на этом многозадачном наборе данных, охватывающем широкий спектр задач.
>В результате модель показала сильную производительность в zero-shot режиме на нескольких стандартных наборах данных, часто превосходя модели, размер которых в 16 раз больше. Помимо этого, подход показал хорошие результаты на подмножестве задач из набора данных BIG-bench, превосходя модели в 6 раз больше своего размера.

![[Pasted image 20240118174939.png]]
Зачем необходимо согласование модели?
Стандартный режим авторегрессионного декодирования, который используется для предварительной подготовки
Для взаимодействия с пользователем необходимо что-то вроде диалогового агента, чтобы модель могла отвечать на вопросы неструктурированным образом.

Данные для обучения содержат несколько выборок вопросов и ответов, которые идут один за другим.
Если ничего не делать с моделью для точной настройки или адаптации, то модель просто решит, что ей нужно продолжить предложение, которое идёт в контексте (часто сложно понять, что хотим получить ответ на вопрос, а не продолжение текста).
Чтобы модель могла понимать формат каждой задачи в понятном для человека формате.
Для Т0 каждое задание описывали с помощью подсказок на естественном языке. Модель смогла обобщить полученное, так как видела много подсказок для каждой из задач.
![[Pasted image 20240118182406.png]]
Предварительная настройка для вывода текста или инструкций.
Для этого необходимо выполнить некоторые действия под наблюдением, т.е. $instruction-tuning$.
![[Pasted image 20240118182848.png]]
>[!info]- Примечание:
>Дальше идёт информация о InstructGPT

---
# InstructGPT

### Этап 1
Собираем информацию: но вместо неструктурированных текстов даём модели некоторые демонстрационные данные о том, как реагировать на вопрос.
Обучаем модель с теми же контролируемыми потерями
![[Pasted image 20240118183611.png]]
Это набор данных для контролируемой тонкой настройки с инструкциями.
![[Pasted image 20240118183910.png]]
![[Pasted image 20240118183935.png]]
![[Pasted image 20240118184034.png]]
Можно идеально настроить модель, используя контролируемую тонкую настройку и контролируемые потери.
![[Pasted image 20240118184149.png]]
Процесс сбора данных дорогостоящий, так как тексты и ответы на них пишут люди, разбирающиеся в требуемых сферах.
И когда проводим обучение со стандартной перекрёстной энтропией - у нас есть только положительные примеры. Наказаний за неправильные ответы нет.
В итоге модель начинает выдавать ответ, который немного похож на правдоподобный.
Проблему может решить обучение с подкреплением. Для этого также используют обратную связь от людей - теперь люди оценивают ответы модели.
![[Pasted image 20240118190710.png]]
Теперь есть хороший и плохой ответ.
И теперь есть примеры того, что не будем рекомендовать модели создавать.
Как добавляют это в функцию потерь?
![[Pasted image 20240118191120.png]]
![[Pasted image 20240118191130.png]]
Модель выдаёт вознаграждение, используя некий набор меток: от худшей к лучшей.
Модель присваивает некоторый регрессионный балл основной модели GPT. Чем больше награда - тем лучше ответ. 
![[Pasted image 20240118192214.png]]
Как оптимизировать модель для получения лучшего вознаграждения?
Вознаграждение не поддаётся дифференциации и нельзя тренироваться с помощью стандартного градиентного спуска. Для этого используют RL, для которой loss необязательно должен быть дифференцируемым. 
Схема обучения: модель теперь является агентом, а окружающая среда - набором действий.


---

Transfer learning (TL) is a technique in machine learning (ML) in which knowledge learned from a task is re-used in order to boost performance on a related task. For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks. This topic is related to the psychological literature on transfer of learning, although practical ties between the two fields are limited. Reusing/transferring information from previously learned tasks to new tasks has the potential to significantly improve learning efficiency.

Since transfer learning makes use of training with multiple objective functions it is related to Cost-sensitive machine learning and multi-objective optimization
[Ссылка](https://habr.com/ru/articles/543412/)
Трансферное обучение в НЛП относится к технике предварительного обучения модели на большом немаркированном наборе данных, а затем ее точной настройке на меньшем помеченном наборе данных для конкретной задачи. Этот подход использует знания, полученные моделью во время предварительного обучения, для достижения более высокой производительности при выполнении последующих задач, часто с меньшим количеством размеченных данных, чем потребовалось бы при обучении с нуля.
# Общий Text-to-Text фреймворк

Наряду с Т5 (Text-To-Text Transfer Transformer) авторы предлагают переосмыслить все NLP задачи и представить их в формате text-to-text, где вход и выход модели представляются текстовыми строками, в отличие от моделей типа BERT, подающие на выход или метку класса, или фрагмент входной последовательности. Предложенный же фреймворк позволяет использовать одну и ту же модель, функцию потерь и гиперпараметры для любой задачи NLP, включая машинный перевод, суммаризацию документов, вопросно-ответные системы, задачу классификации (например, анализ тональности). Модель Т5 можно использовать даже для задачи регрессии, обучив ее предсказывать строковое представление числа вместо самого числа.
![[Pasted image 20240117214316.png]]
_Диаграмма предложенного фреймворка. Для каждой из рассматриваемых задач на вход модели подается текст; обучение состоит в генерации некоторого целевого текста. Это позволяет использовать одни и те же модель, функцию потерь и гиперпараметры для решения различных задач, включая перевод (зеленым), лингвистическую состоятельность (красным), семантическую близость предложений (желтым), суммаризацию документа (синим). Это также позволяет иметь стандартный набор тестов для методов, рассмотренных в эмпирическом исследовании._

# Большой набор данных для обучения (С4)

Важная составляющая трансферного обучения – это наличие неразмеченного набора данных, используемого для предварительного обучения. Для того, чтобы точно измерить эффективность масштабирования предварительного обучения, необходимо иметь не просто качественные и разнообразные данные, но и большие их объемы. Существующие наборы данных не соответствуют сразу всем этим трем критериям: например, тексты из [Википедии](https://www.wikipedia.org/) обычно высокого качества, но довольно однообразны стилистически и имеют достаточно скромный общий объем. В то же время тексты [Common Crawl](https://commoncrawl.org/) имеют просто огромный размер и очень разнообразный состав, но их качество оставляет желать лучшего.

Для того, чтобы удовлетворить требованиям, описанным выше, был разработан Colossal Clean Crawled Corpus (C4) – вычищенная версия Common Crawl, объем которой на два порядка превышает объем Википедии. Процесс очистки набора данных включал удаление дубликатов, неполных предложений, а также неприемлемых или мусорных текстов. Подобная фильтрация способствовала получению лучших результатов в прикладных задачах, в то время как большой объем позволил увеличить размер модели без риска переобучения. С4 доступен в [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/c4).

# Систематическое исследование методологии трансферного обучения

С помощью предложенного T5 text-to-text фреймворка и нового набора данных для предварительного обучения С4 авторы смогли исследовать довольно большое количество идей и методов, предложенных в сфере трансферного обучения в NLP в последние несколько лет. Все детали исследования можно найти в соответствующей статье, включая эксперименты:
- _архитектурой_, в ходе которых выяснилось, что модели с энкодером и декодером обычно превосходят языковые модели с одним декодером;
- _целями предварительного обучения_, в ходе чего подтвердилось, что задачи типа заполни_пропуск (где модель обучается восстанавливать пропущенные слова во входном тексте) являются наилучшим решением и что самым важным фактором оказываются затраты на вычисление;
- _неразмеченными наборами данных_, в ходе которых удалось показать, что обучение на данных определенной предметной области может оказаться полезным, но что предварительное обучение на небольших наборах данных может привести к переобучению;
- _стратегиями обучения_, в ходе которых выяснилось, что многозадачное обучение может быть сравнимо с предварительным обучением и последующей тонкой настройкой, однако первое требует внимательного выбора частоты обучения модели на определенную задачу;
- _масштабами_, в ходе которых сравнивались увеличение размера модели, времени обучения и числа моделей в ансамбле для определения наиболее эффективного использования имеющейся вычислительной мощности.

  

# Инсайты + Масштаб = State-of-the-Art

Для нахождения существующих ограничений трансферного обучения в NLP авторы проделали финальный набор экспериментов, в которых они объединили все лучшие методы, определенные в их систематическом исследовании, и масштабировали их подход с помощью [TPU-ускорителей Google Cloud](https://cloud.google.com/tpu/). Крупнейшая модель имела 11 миллиардов параметров и достигла уровня state-of-the-art в рамках бенчмарков [GLUE](https://gluebenchmark.com/), [SuperGLUE](https://super.gluebenchmark.com/), [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) и [CNN/Daily Mail](https://github.com/abisee/cnn-dailymail). Особенно неожиданным результатом оказалось достижение околочеловеческого уровня в понимании естественного языка в рамках бенчмарка SuperGLUE, который разрабатывался намеренно сложным для моделей машинного обучения, но легким для человека.
# Расширения

Т5 достаточно гибка в применении для решения различных задач помимо тех, что указаны в статье, и зачастую справляется с этим с большим успехом. Ниже рассматривается использование Т5 для двух новых задач: ответы на вопросы без предварительного обучения на специальном корпусе вопросов-ответов (Closed-book question answering) и генерация текста для заполнения пропусков переменной длины.

## Ответы на общие вопросы

Один из вариантов использования text-to-text фреймворка заключается в понимании прочитанного текста: модели подается некоторый контекст и вопрос, ответ на который ей необходимо научиться находить в заданном контексте. Например, можно подать на вход модели статью из Википедии об [урагане Конни](https://en.wikipedia.org/wiki/Hurricane_Connie) вместе с вопросом: «Когда произошел ураган Конни?». После чего модель будет учиться находить в статье нужную дату: «3 августа 1955 года». Этот подход помог получить наилучшие результаты на стендфордском вопросно-ответном датасете (SQuAD).

Как продемонстрировано в [Colab-ноутбуке](https://colab.research.google.com/github/google-research/text-to-text-transfer-transformer/blob/master/notebooks/t5-trivia.ipynb) и сопровождающей [статье](https://arxiv.org/abs/2002.08910), авторы обучают Т5 отвечать на тривиальные вопросы в более сложной реализации, когда у модели нет доступа к внешнему знанию. Другими словами, чтобы ответить на вопрос, Т5 может использовать только те знания, которые хранятся в параметрах, полученных во время предварительного обучения без учителя. Это можно рассматривать как ограниченный вариант [общей вопросно-ответной системы](https://en.wikipedia.org/wiki/Question_answering#Open_domain_question_answering).
![[Pasted image 20240117215515.png]]
_Во время предварительного обучения Т5 учится заполнять очищенные слоты текста (отмечено как $<M>$) в текстах корпуса С4. Для применения Т5 для задачи ответа на общие вопросы была проведена тонкая настройка модели для получения ответа без сопровождения дополнительного контекста или прочей информации. Это заставило Т5 отвечать на вопросы на основе тех «знаний», которые она получила в ходе предварительного обучения._  
  
Т5 на удивление хорошо справляется с этой задачей. Модель с 11 миллиардами параметров генерирует точный текст ответа в 50.1%, 37.4% и 34.5% случаев в заданиях TriviaQA, WebQuestions и Natural Questions соответственно. Для сравнения: команда разработчиков Т5 играла против модели в викторине Pub trivia challenge и проиграла! Попробуйте сами, нажав на анимацию ниже.

The T0 model, also known as "instruction-tuning", builds upon the concept of transfer learning by fine-tuning models like T5 on a mixture of tasks formulated as prompting tasks. Instead of fine-tuning a model on a single task, T0 is fine-tuned on a diverse range of tasks using a multitask learning approach. The model learns to follow instructions given in natural language, which enables it to generalize across tasks without additional fine-tuning 1.