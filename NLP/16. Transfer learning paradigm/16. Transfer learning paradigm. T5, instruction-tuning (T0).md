[Лекция L11](https://www.youtube.com/watch?v=UIoMclQuSG8&list=PLH5AUD0BdzX7p017wqAN85gjARtrk73Wa&index=37)

==лекция==

![[Screen Shot 2024-01-19 at 19.42.44.png]]
Объединили BERT и GPT (как будто обратно целый трансформер собрали?)
>[!info]- мнение ==чатика== по этому вопросу:
>Модель BART (англ. Bidirectional and Auto-Regressive Transformers) действительно базируется на архитектуре трансформера, но имеет несколько ключевых отличий от классического трансформера, представленного в статье "Attention is All You Need". Вот основные отличия:
>1. **Обучение с использованием восстановления текста (denoising autoencoder):**
>   - Вместо того, чтобы предсказывать следующее слово в последовательности (как в традиционных трансформерах), модель BART обучается восстанавливать оригинальный текст из "зашумленной" версии. Это достигается случайным образом заменой и перестановкой слов в предложениях.
>   - Этот подход к обучению позволяет модели учить более глубокие и обобщенные представления о языке.
>2. кажется тут он насочинял: ==**Bidirectional (двунаправленное) кодирование:** Модель BART использует двунаправленное кодирование, что означает, что она способна учитывать контекст как слева, так и справа от текущего слова в процессе кодирования. Это достигается использованием механизма автокодирования (autoencoder), где она подается как на входе, так и на выходе в обучении.==
>3. **Задача перевода:**
>   - BART предназначен, в первую очередь, для задачи генерации текста и перевода. Он обучается на парах предложений в исходном и целевом языках.
>4. **Генерация текста с обучением только декодера:**
>   - В отличие от традиционного трансформера, где энкодер и декодер обучаются параллельно, в BART только декодер получает обучение. Энкодер используется для получения представлений входного текста, которые затем передаются декодеру для генерации целевого текста.
>В целом, хотя BART и базируется на архитектуре трансформера, его спецификации и метод обучения делают его уникальным и подходящим для определенных задач, таких как генерация текста и машинный перевод.

[Описание BART](https://huggingface.co/transformers/v2.11.0/model_doc/bart.html) на Hugging Face: ![[Pasted image 20240119212958.png]]
>[!info]- перевод:
>Bart использует стандартную архитектуру seq2seq/машинного перевода с двунаправленным кодером (как BERT) и декодером слева направо (как GPT).
>Задача предварительного обучения включает случайную перестановку порядка исходных предложений и новую схему заполнения, при которой фрагменты текста заменяются одной лексемой-маской.
>BART особенно эффективен при тонкой настройке для генерации текста, но также хорошо работает в задачах понимания. Он сравнялся по производительности с RoBERTa при сопоставимых ресурсах обучения на GLUE и SQuAD, а также достиг новых передовых результатов в ряде задач абстрактного диалога, ответов на вопросы и обобщения, причем прирост составил до 6 ROUGE.

Несколько форматов:![[Screen Shot 2024-01-19 at 20.04.58.png]]
Насколько я понимаю, основная идея, заложенная в Т5 такая, что модель строят как BART, и подают в неё все данные для обучения в виде только текстов. Т.е. все задачи, на которых ранее тренировали BERT преобразованы в задачи Text-to-text с помощью текстовых инструкций. К примеру, если задача перевода, то мы не просто подаем на вход и выход предложения из разных языков, а на вход дополняем еще и постановку задачи в виде текстовой инструкции, типа "Перевод с английского на немецкий..." и далее исходное предложение. Модель учится выполнять разнородные языковые задачи, такие как перевод, классификацию, Q&A, суммаризацию, (даже регрессию) и др. имея одну и ту же структуру для всех задач. 

**Relative position embeddings** - instead of long matrix of embeddings (that combine semantic and positional information) it maintains two distinct matrices. Attention performs two attention computations for semantic and positional matrices (positional embeddings keep distance between the tokens in the attn mechanism, not the abs position in the seq).

Обучают их с помощью кросс-энтропии. При обучении добавляют в исходные данные около 15% шума, что улучшает способность модели понимать не совсем точные данные при инференсе.
![[Pasted image 20240120051559.png]]
Происходит метаобучение - обучение нескольких задач.
Используя эту форму для обучения множества задач одновременно.
Метаобучение - процедура, при которой различные задачи помогают друг другу, потому что у них есть некоторая базовая схожая информация, которую они используют. И как только модель подвергается воздействию обеих этих задач своего рода первая задача заставляет модель усвоить некоторые знания, которые были бы полезны для второй задачи. При этом извлечь уроки из второго задания было бы не столь просто, как извлечь их из первого.

Например, если вы тренируете машинный перевод и в тоже время вы тренируете некоторую классификацию на другом наборе данных и эта классификация содержит несколько иностранных слов, то вспомогательная задача перевода поможет задаче классификации лучше справиться с иностранными словами, так как задачи классификации недостаточно для того, чтобы выучить иностранные слова сами по себе.

По утверждению авторов статьи, такое построение на естественном языке помогает модели обобщать одну задачу с другой с помощью инструкций на естественном языке.
Таким образом, данные инструкции помогают *программисту* (модели?) лучше понять свойства каждой задачи.
[Лекция L12](https://www.youtube.com/watch?v=7hud9GQIOP0&list=PLH5AUD0BdzX7p017wqAN85gjARtrk73Wa&index=38)

---

# Про Т0

>[!info]- кратко от ==чатика== по [статье](https://arxiv.org/abs/2110.08207)
> Статья под названием "Multitask Prompted Training Enables Zero-Shot Task Generalization" исследует возможность создания моделей машинного обучения, которые могут обобщать и выполнять задания, на которых они не обучались (так называемый zero-shot). В работе рассматривается гипотеза о том, что такое обобщение может быть результатом многозадачного обучения в процессе предварительного обучения языковых моделей.
>Авторы разработали систему, которая позволяет легко преобразовывать любые задачи обработки естественного языка в форму, удобную для чтения человеком, и использовали её для создания набора данных с разнообразными формулировками. Затем они дообучили предварительно обученную модель кодировщика-декодера на этом многозадачном наборе данных, охватывающем широкий спектр задач.
>В результате модель показала сильную производительность в zero-shot режиме на нескольких стандартных наборах данных, часто превосходя модели, размер которых в 16 раз больше. Помимо этого, подход показал хорошие результаты на подмножестве задач из набора данных BIG-bench, превосходя модели в 6 раз больше своего размера.

В отличии от Т5 здесь текстовые инструкции заменены на обычные промпты на естественном языке, т.е. мы не пишем теперь инструкцию в виде "перевод с немецкого на английский...", а даем текст, и дописываем просто в конце или в начале обычную просьбу в виде "не мог бы ты перевести это для меня на русский?" ==обсудить==
![[Pasted image 20240120050043.png]]
Зачем необходимо согласование модели?
Стандартный режим авторегрессионного декодирования, который используется для предварительной подготовки
Для взаимодействия с пользователем необходимо что-то вроде диалогового агента, чтобы модель могла отвечать на вопросы неструктурированным образом.

Данные для обучения содержат несколько выборок вопросов и ответов, которые идут один за другим.
Если ничего не делать с моделью для точной настройки или адаптации, то модель просто решит, что ей нужно продолжить предложение, которое идёт в контексте (часто сложно понять, что хотим получить ответ на вопрос, а не продолжение текста).
Чтобы модель могла понимать формат каждой задачи в понятном для человека формате.
Для Т0 каждое задание описывали с помощью подсказок на естественном языке. Модель смогла обобщить полученное, так как видела много подсказок для каждой из задач.
![[Pasted image 20240118182406.png]]
Предварительная настройка для вывода текста или инструкций.
Для этого необходимо выполнить некоторые действия под наблюдением, т.е. $instruction-tuning$.
![[Pasted image 20240118182848.png]]
>[!info]- Примечание:
>Дальше идёт информация о InstructGPT

---
# InstructGPT

### Этап 1
Собираем информацию: но вместо неструктурированных текстов даём модели некоторые демонстрационные данные о том, как реагировать на вопрос.
Обучаем модель с теми же контролируемыми потерями
![[Pasted image 20240118183611.png]]
Это набор данных для контролируемой тонкой настройки с инструкциями.
![[Pasted image 20240118183910.png]]
![[Pasted image 20240118183935.png]]
![[Pasted image 20240118184034.png]]
Можно идеально настроить модель, используя контролируемую тонкую настройку и контролируемые потери.
![[Pasted image 20240118184149.png]]
Процесс сбора данных дорогостоящий, так как тексты и ответы на них пишут люди, разбирающиеся в требуемых сферах.
И когда проводим обучение со стандартной перекрёстной энтропией - у нас есть только положительные примеры. Наказаний за неправильные ответы нет.
В итоге модель начинает выдавать ответ, который немного похож на правдоподобный.
Проблему может решить обучение с подкреплением. Для этого также используют обратную связь от людей - теперь люди оценивают ответы модели.
![[Pasted image 20240118190710.png]]
Теперь есть хороший и плохой ответ.
И теперь есть примеры того, что не будем рекомендовать модели создавать.
Как добавляют это в функцию потерь?
![[Pasted image 20240118191120.png]]
![[Pasted image 20240118191130.png]]
Модель выдаёт вознаграждение, используя некий набор меток: от худшей к лучшей.
Модель присваивает некоторый регрессионный балл основной модели GPT. Чем больше награда - тем лучше ответ. 
![[Pasted image 20240118192214.png]]
Как оптимизировать модель для получения лучшего вознаграждения?
Вознаграждение не поддаётся дифференциации и нельзя тренироваться с помощью стандартного градиентного спуска. Для этого используют RL, для которой loss необязательно должен быть дифференцируемым. 
Схема обучения: модель теперь является агентом, а окружающая среда - набором действий - источник и состояние генерации на данный момент.
Теперь есть исходная последовательность и скрытый вектор нашей модели.
### Как тренируемся?
Есть наша модель вознаграждения и мы можем подключить любой алгоритм RL, чтобы максимизировать данную функцию вознаграждения. 
![[Pasted image 20240118200946.png]]
Описание работы:
Генерация нескольких ответов из окружающей среды - несколько траекторий (objective).
Траектория (objective) - это выборки из N по некоторым подсказкам. Это выборка по методу Монте Карло.
Для обучения RL нужны награды за каждый эпизод.
![[Pasted image 20240118202327.png]]
Эти выборки подобны обычным выборкам из трансформеров.
Теперь есть полные данные для обучения с подкреплением.
![[Pasted image 20240118202616.png]]
Надо обучить агента чаще генерировать ответы с высокими наградами.
Как это оптимизировать?
![[Pasted image 20240118202729.png]]
Стандартный метод: policy gradient
 Policy - вероятность предсказать одно текущее слово после префикса. 
 Policy - распределение вероятности следующего токена.
 ![[Pasted image 20240118203558.png]]
 Хотелось бы оптимизировать ожидаемое вознаграждение (в формуле $J$) с учётом policy и objective.
 Первое распределение в формуле - распределение префиксов в вопросах, второе  - распределение возможных ответов.
Мы хотим максимизировать награду с помощи настройки параметров.
RL основано на идеи, что мы оцениваем что-то с помощью Монте Карло, то есть всё необходимо свести к тому, чтобы это можно было оценить с помощью Монте Карло.
И что policy based methods, мы хотим обучить параметры модели (агента) относительно функции потерь.
![[Pasted image 20240118204052.png]]
Если мы сможем вычислить градиент и провести оценку методом Монте Карло, то получим такое вознаграждение
![[Pasted image 20240118204258.png]]
![[Pasted image 20240118204345.png]]
Цель policy gradient состоит в том, чтобы переписать $J$ по отношению к $\vartheta$, таким образом, чтобы градиент был совместим с выборкой.
![[Pasted image 20240118204600.png]]
![[Pasted image 20240118204612.png]]
![[Pasted image 20240118204726.png]]
![[Pasted image 20240118204737.png]]
![[Pasted image 20240118204803.png]]
![[Pasted image 20240118204823.png]]
![[Pasted image 20240118204912.png]]
![[Pasted image 20240118205000.png]]
![[Pasted image 20240118205028.png]]
У нас есть границы по состоянию и границы по траектории (objective).
![[Pasted image 20240118205139.png]]
![[Pasted image 20240118205208.png]]
Затем выполняем подъём по градиенту в соответствии с заданными параметрами.
![[Pasted image 20240118205300.png]]
![[Pasted image 20240118205336.png]]
![[Pasted image 20240118205444.png]]

---

Transfer learning (TL) is a technique in machine learning (ML) in which knowledge learned from a task is re-used in order to boost performance on a related task. For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks. This topic is related to the psychological literature on transfer of learning, although practical ties between the two fields are limited. Reusing/transferring information from previously learned tasks to new tasks has the potential to significantly improve learning efficiency.

Since transfer learning makes use of training with multiple objective functions it is related to Cost-sensitive machine learning and multi-objective optimization
[Ссылка](https://habr.com/ru/articles/543412/)
Трансферное обучение в НЛП относится к технике предварительного обучения модели на большом немаркированном наборе данных, а затем ее точной настройке на меньшем помеченном наборе данных для конкретной задачи. Этот подход использует знания, полученные моделью во время предварительного обучения, для достижения более высокой производительности при выполнении последующих задач, часто с меньшим количеством размеченных данных, чем потребовалось бы при обучении с нуля.
# Общий Text-to-Text фреймворк

Наряду с Т5 (Text-To-Text Transfer Transformer) авторы предлагают переосмыслить все NLP задачи и представить их в формате text-to-text, где вход и выход модели представляются текстовыми строками, в отличие от моделей типа BERT, подающие на выход или метку класса, или фрагмент входной последовательности. Предложенный же фреймворк позволяет использовать одну и ту же модель, функцию потерь и гиперпараметры для любой задачи NLP, включая машинный перевод, суммаризацию документов, вопросно-ответные системы, задачу классификации (например, анализ тональности). Модель Т5 можно использовать даже для задачи регрессии, обучив ее предсказывать строковое представление числа вместо самого числа.
![[Pasted image 20240117214316.png]]
_Диаграмма предложенного фреймворка. Для каждой из рассматриваемых задач на вход модели подается текст; обучение состоит в генерации некоторого целевого текста. Это позволяет использовать одни и те же модель, функцию потерь и гиперпараметры для решения различных задач, включая перевод (зеленым), лингвистическую состоятельность (красным), семантическую близость предложений (желтым), суммаризацию документа (синим). Это также позволяет иметь стандартный набор тестов для методов, рассмотренных в эмпирическом исследовании._

# Большой набор данных для обучения (С4)

Важная составляющая трансферного обучения – это наличие неразмеченного набора данных, используемого для предварительного обучения. Для того, чтобы точно измерить эффективность масштабирования предварительного обучения, необходимо иметь не просто качественные и разнообразные данные, но и большие их объемы. Существующие наборы данных не соответствуют сразу всем этим трем критериям: например, тексты из [Википедии](https://www.wikipedia.org/) обычно высокого качества, но довольно однообразны стилистически и имеют достаточно скромный общий объем. В то же время тексты [Common Crawl](https://commoncrawl.org/) имеют просто огромный размер и очень разнообразный состав, но их качество оставляет желать лучшего.

Для того, чтобы удовлетворить требованиям, описанным выше, был разработан Colossal Clean Crawled Corpus (C4) – вычищенная версия Common Crawl, объем которой на два порядка превышает объем Википедии. Процесс очистки набора данных включал удаление дубликатов, неполных предложений, а также неприемлемых или мусорных текстов. Подобная фильтрация способствовала получению лучших результатов в прикладных задачах, в то время как большой объем позволил увеличить размер модели без риска переобучения. С4 доступен в [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/c4).

# Систематическое исследование методологии трансферного обучения

С помощью предложенного T5 text-to-text фреймворка и нового набора данных для предварительного обучения С4 авторы смогли исследовать довольно большое количество идей и методов, предложенных в сфере трансферного обучения в NLP в последние несколько лет. Все детали исследования можно найти в соответствующей статье, включая эксперименты:
- _архитектурой_, в ходе которых выяснилось, что модели с энкодером и декодером обычно превосходят языковые модели с одним декодером;
- _целями предварительного обучения_, в ходе чего подтвердилось, что задачи типа заполни_пропуск (где модель обучается восстанавливать пропущенные слова во входном тексте) являются наилучшим решением и что самым важным фактором оказываются затраты на вычисление;
- _неразмеченными наборами данных_, в ходе которых удалось показать, что обучение на данных определенной предметной области может оказаться полезным, но что предварительное обучение на небольших наборах данных может привести к переобучению;
- _стратегиями обучения_, в ходе которых выяснилось, что многозадачное обучение может быть сравнимо с предварительным обучением и последующей тонкой настройкой, однако первое требует внимательного выбора частоты обучения модели на определенную задачу;
- _масштабами_, в ходе которых сравнивались увеличение размера модели, времени обучения и числа моделей в ансамбле для определения наиболее эффективного использования имеющейся вычислительной мощности.

  

# Инсайты + Масштаб = State-of-the-Art

Для нахождения существующих ограничений трансферного обучения в NLP авторы проделали финальный набор экспериментов, в которых они объединили все лучшие методы, определенные в их систематическом исследовании, и масштабировали их подход с помощью [TPU-ускорителей Google Cloud](https://cloud.google.com/tpu/). Крупнейшая модель имела 11 миллиардов параметров и достигла уровня state-of-the-art в рамках бенчмарков [GLUE](https://gluebenchmark.com/), [SuperGLUE](https://super.gluebenchmark.com/), [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) и [CNN/Daily Mail](https://github.com/abisee/cnn-dailymail). Особенно неожиданным результатом оказалось достижение околочеловеческого уровня в понимании естественного языка в рамках бенчмарка SuperGLUE, который разрабатывался намеренно сложным для моделей машинного обучения, но легким для человека.
# Расширения

Т5 достаточно гибка в применении для решения различных задач помимо тех, что указаны в статье, и зачастую справляется с этим с большим успехом. Ниже рассматривается использование Т5 для двух новых задач: ответы на вопросы без предварительного обучения на специальном корпусе вопросов-ответов (Closed-book question answering) и генерация текста для заполнения пропусков переменной длины.

## Ответы на общие вопросы

Один из вариантов использования text-to-text фреймворка заключается в понимании прочитанного текста: модели подается некоторый контекст и вопрос, ответ на который ей необходимо научиться находить в заданном контексте. Например, можно подать на вход модели статью из Википедии об [урагане Конни](https://en.wikipedia.org/wiki/Hurricane_Connie) вместе с вопросом: «Когда произошел ураган Конни?». После чего модель будет учиться находить в статье нужную дату: «3 августа 1955 года». Этот подход помог получить наилучшие результаты на стендфордском вопросно-ответном датасете (SQuAD).

Как продемонстрировано в [Colab-ноутбуке](https://colab.research.google.com/github/google-research/text-to-text-transfer-transformer/blob/master/notebooks/t5-trivia.ipynb) и сопровождающей [статье](https://arxiv.org/abs/2002.08910), авторы обучают Т5 отвечать на тривиальные вопросы в более сложной реализации, когда у модели нет доступа к внешнему знанию. Другими словами, чтобы ответить на вопрос, Т5 может использовать только те знания, которые хранятся в параметрах, полученных во время предварительного обучения без учителя. Это можно рассматривать как ограниченный вариант [общей вопросно-ответной системы](https://en.wikipedia.org/wiki/Question_answering#Open_domain_question_answering).
![[Pasted image 20240117215515.png]]
_Во время предварительного обучения Т5 учится заполнять очищенные слоты текста (отмечено как $<M>$) в текстах корпуса С4. Для применения Т5 для задачи ответа на общие вопросы была проведена тонкая настройка модели для получения ответа без сопровождения дополнительного контекста или прочей информации. Это заставило Т5 отвечать на вопросы на основе тех «знаний», которые она получила в ходе предварительного обучения._  
  
Т5 на удивление хорошо справляется с этой задачей. Модель с 11 миллиардами параметров генерирует точный текст ответа в 50.1%, 37.4% и 34.5% случаев в заданиях TriviaQA, WebQuestions и Natural Questions соответственно. Для сравнения: команда разработчиков Т5 играла против модели в викторине Pub trivia challenge и проиграла! Попробуйте сами, нажав на анимацию ниже.

The T0 model, also known as "instruction-tuning", builds upon the concept of transfer learning by fine-tuning models like T5 on a mixture of tasks formulated as prompting tasks. Instead of fine-tuning a model on a single task, T0 is fine-tuned on a diverse range of tasks using a multitask learning approach. The model learns to follow instructions given in natural language, which enables it to generalize across tasks without additional fine-tuning 1.