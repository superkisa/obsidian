https://lena-voita.github.io/nlp_course/text_classification.html#nn_models_cnn
CNN in text preprossesing using, for example, for tasks of finding some patterns througth the text (the task of classifying positive/negative sentiment of the text). 
Following the intuition above, <u>we want to detect some patterns, but we don't care much where exactly these patterns are</u>. This behavior is implemented with <u><b>two layers</u></b>:
- **convolution**: finds matches with patterns (as the cat head we saw above);
- **pooling**: aggregates these matches over positions (either locally or globally).
![[Pasted image 20240114201322.png]]
Differently from images, texts have only one dimension: here a *convolution is one-dimensional.
![[cnn_filter_reads_text.gif]]

#### Convolution is a Linear Operation Applied to Each Window
![[Pasted image 20240114203337.png]]
A convolution is a linear layer (followed by a non-linearity) applied to each input window.
- $(x_1, ... , x_n)$ - representations of the input words, $x_i\in \mathbb{R}^d$;
- $d$ (input channels) - size of an input embedding;
- $k$ (kernel size) - the length of a convolution window (on the illustration, $k=3$);
- $m$ (output channels) - number of convolution filters (i.e., number of channels produced by the convolution).
Then a convolution is a linear layer $W\in\mathbb{R}^{(k\cdot d)\times m}$. For a $k$-sized window $(x_i, ... , x_{i+k-1})$, the convolution takes the concatenation of these vectors
$$u_i = [x_i, \dots x_{i+k-1}]\in\mathbb{R}^{k\cdot d}$$
and multiplies by the convolution matrix:
$$F_i = u_i \times W.$$
Each Filter Extracts a Feature. A filter takes vector representations in a current window and transforms them linearly into a single feature. For a window $u_i = [x_i, \dots x_{i+k-1}]\in\mathbb{R}^{k\cdot d}$ a filter $f\in\mathbb{R}^{k\cdot d}$ computes dot product: $F_i^{(f)} = (f, u_i)$. The number $F_i^{(f)}$ (the extracted "feature") is a result of applying the filter $f$ to the window $(x_i, \dots x_{i+k-1})$.
![[several_filters_read.gif]]
![[Pasted image 20240115000347.png]]

#### Pooling Operation
A pooling layer <u>summarises the features in some region</u>. Pooling layers are used to reduce the input dimension, and, therefore, to <u>reduce the number of parameters used by the network</u>.

The most popular is <u><b>max-pooling</u></b>: it takes maximum over each dimension, i.e. takes the maximum value of each feature.
![[Pasted image 20240115001001.png]]
<u><b>Mean-pooling</u></b> works similarly but computes mean over each feature instead of maximum.
