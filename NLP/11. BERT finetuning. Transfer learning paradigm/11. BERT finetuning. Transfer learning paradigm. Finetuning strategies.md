Transfer learning (TL) is a technique in machine learning (ML) in which knowledge learned from a task is re-used in order to boost performance on a related task. For example, for image classification, knowledge gained while learning to recognize cars could be applied when trying to recognize trucks. This topic is related to the psychological literature on transfer of learning, although practical ties between the two fields are limited. Reusing/transferring information from previously learned tasks to new tasks has the potential to significantly improve learning efficiency.

Since transfer learning makes use of training with multiple objective functions it is related to Cost-sensitive machine learning and multi-objective optimization
[Ссылка](https://habr.com/ru/articles/543412/)
Трансферное обучение в НЛП относится к технике предварительного обучения модели на большом немаркированном наборе данных, а затем ее точной настройке на меньшем помеченном наборе данных для конкретной задачи. Этот подход использует знания, полученные моделью во время предварительного обучения, для достижения более высокой производительности при выполнении последующих задач, часто с меньшим количеством размеченных данных, чем потребовалось бы при обучении с нуля.