[Seq2Seq and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)
[Attention for Neural Networks, Clearly Explained](https://www.youtube.com/watch?v=PSs6nxngL6k)

==забираю вопрос, делаю, Евгений==

# Attention

## The Problem of Fixed Encoder Representation

Problem: Fixed source representation is suboptimal: (i) for the encoder, it is hard to compress the sentence; (ii) for the decoder, different information may be relevant at different steps.

![](https://lena-voita.github.io/resources/lectures/seq2seq/attention/bottleneck-min.png)

In the models we looked at so far, the encoder compressed the whole source sentence into a single vector. This can be very hard - the number of possible source sentences (hence, their meanings) is infinite. When the encoder is forced to put all information into a single vector, it is likely to forget something.

Not only it is hard for the encoder to put all information into a single vector - this is also hard for the decoder. The decoder sees only one representation of source. However, at each generation step, different parts of source can be more useful than others. But in the current setting, the decoder has to extract relevant information from the same fixed representation - hardly an easy thing to do.

## Attention: A High-Level View

Attention was introduced in the paper [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf) to address the fixed representation problem.
[Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#:~:text=fixed%20representation%20problem.-,Attention,-%3A%20At%20different%20steps): At different steps, let a model "focus" on different parts of the input.

An attention mechanism is a part of a neural network. At each decoder step, it decides which source parts are more important. In this setting, the encoder does not have to compress the whole source into a single vector - it gives representations for all source tokens (for example, all RNN states instead of the last one).

![](https://lena-voita.github.io/resources/lectures/seq2seq/attention/general_scheme-min.png)

At each decoder step, attention

- receives attention input: a decoder state ℎ� and all encoder states �1, �2, ..., ��;
- computes attention scores  
    For each encoder state ��, attention computes its "relevance" for this decoder state ℎ�. Formally, it applies an attention function which receives one decoder state and one encoder state and returns a scalar value ◂⋅▸(◂⋅▸;
- computes attention weights: a probability distribution - softmax applied to attention scores;
- computes attention output: the weighted sum of encoder states with attention weights.

The general computation scheme is shown below.