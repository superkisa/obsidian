GPT:
1. pre-training
2. supervised fine-tuning
	1. initial stage: manually written by labelers; later stage: from prompts submitted by users via opecAI API
	2. for a selected format of instruction: cross-entropy loss training
3. reward model training
	1. model generates few answers and ppl rate it
		1. this step is needed because training only on positive examples promotes hallucinations 
	2. The loss function in reward model training compares the predicted rewards (output by the model) with the rewards expected from the true environment.
		- It quantifies how well the model's predictions align with the actual rewards that would be obtained in the environment
	- reward function is output from model trained on human answers
1. RL optimisation with respect to reward model on policy
	1. we genrate some trajectories from env. that are seq-s from some prompt (sample of trajectories)
	2. compute reward for each response
	3. train to increase probability of responses with high reward
- 
- Pre-training
	- multi-task training
- Alignment
	- we want the model to answer the questions (do the tasks), not to continue text generation

![[Screen Shot 2024-01-20 at 11.01.02.png]]

![[Screen Shot 2024-01-20 at 11.00.39.png]]
![[Screen Shot 2024-01-20 at 11.02.58.png]]![[Screen Shot 2024-01-20 at 11.08.33.png]]![[Screen Shot 2024-01-20 at 11.10.37.png]]![[Screen Shot 2024-01-20 at 11.12.57.png]]![[Screen Shot 2024-01-20 at 11.13.30.png]]![[Screen Shot 2024-01-20 at 11.14.08.png]]![[Screen Shot 2024-01-20 at 11.16.39.png]]![[Screen Shot 2024-01-20 at 11.30.09.png]]![[Screen Shot 2024-01-20 at 11.30.35.png]]
![[Screen Shot 2024-01-20 at 11.33.33.png]]![[Screen Shot 2024-01-20 at 11.33.56.png]]![[Screen Shot 2024-01-20 at 11.34.38.png]]![[Screen Shot 2024-01-20 at 11.36.04.png]]![[Screen Shot 2024-01-20 at 11.36.24.png]]![[Screen Shot 2024-01-20 at 11.36.39.png]]![[Screen Shot 2024-01-20 at 11.37.34.png]]![[Screen Shot 2024-01-20 at 11.37.48.png]]![[Screen Shot 2024-01-20 at 11.38.28.png]]![[Screen Shot 2024-01-20 at 11.39.08.png]]![[Screen Shot 2024-01-20 at 11.39.46.png]]