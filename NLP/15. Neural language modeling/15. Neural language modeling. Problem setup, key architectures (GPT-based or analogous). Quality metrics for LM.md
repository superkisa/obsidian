Берем [отличнейшую статью Аламмара](https://jalammar.github.io/illustrated-gpt2) (с [переводом](https://habr.com/ru/post/490842/)) и видим там:
 - что такое [Neural language modeling](https://jalammar.github.io/illustrated-gpt2/#:~:text=a%20language%20model%3F-,What%20is%20a%20Language%20Model,-In%20The%20Illustrated)
 - перечисление архитектур![[Pasted image 20240118185535.png]]![[Pasted image 20240118185607.png]]
 от себя добавлю, что там еще и все виды RNN подходят.
 - множество инфы про внутреннее устройство этих архитектур
 - кстати здесь же, мне более понятное объяснение механизмов [Self-Attention](https://jalammar.github.io/illustrated-gpt2/#:~:text=Self%2DAttention%20Recap). Это еще не все, далее [еще подробнее, все по действиям и молекулам](https://jalammar.github.io/illustrated-gpt2/#part-2-illustrated-self-attention)
 - но вот про метрики там нет, но у нас уже было про метрики в [[6. Machine translation. Problem setup, training and inference procedures. Quality metrics for MT | конце 6-го вопроса]]