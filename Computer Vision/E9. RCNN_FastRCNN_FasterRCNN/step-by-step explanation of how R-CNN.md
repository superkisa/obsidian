The R-CNN training process involves several steps, and while there aren't explicit mathematical formulas provided in the sources, the process can be described algorithmically. Here's a general overview of the R-CNN training process, extrapolated from the sources provided:

1. **Preparation of the Dataset**:
    - A dataset with pre-labeled ground truth bounding boxes for objects of interest is prepared. The dataset should consist of images and corresponding annotations that define the location and class of each object within the images.

2. **Region Proposals**:
    - Using a selective search or similar algorithm, generate region proposals that might contain objects.

3. **Feature Extraction**:
    - Each region proposal is resized and fed into a pre-trained CNN (e.g., trained on ImageNet or CIFAR-10) to extract feature vectors.

4. **SVM Training**:
    - A Support Vector Machine (SVM) is trained on the extracted features to classify whether each region contains an object of a particular class.

5. **Bounding Box Regression**:
    - In parallel with SVM training, a regression model is trained to refine the bounding boxes of the region proposals, ensuring a better fit for the actual objects.

6. **Training the Model**:
    - The CNN, SVM, and regression models are combined into the R-CNN architecture. The training involves fine-tuning the CNN with the region proposals and ground truth data, which is performed using backpropagation and an optimization algorithm such as Stochastic Gradient Descent (SGD).
    - Training options are specified, which include learning rate, momentum, learning rate schedule, regularization, batch size, and the number of epochs.
    - Positive and negative overlap ranges are defined to determine which region proposals should be used as positive examples (containing the object) and negative examples (background or non-object).

7. **Training Execution**:
    - The training is executed using a function such as `trainRCNNObjectDetector` in MATLAB, which takes the dataset, pre-trained CNN, and training options as input.
    - During training, the network weights are fine-tuned using image patches extracted from the ground truth data. The training process can be expedited using parallel computing resources or a GPU.

8. **Model Evaluation**:
    - After training, the model's performance is evaluated using a test set or validation set to assess its accuracy and robustness. The evaluation metrics often include precision, recall, F1-score, and Intersection over Union (IoU).

9. **Debugging and Visualization**:
    - Debugging tips include visualizing the feature maps generated by the CNN to understand which parts of the image are activating the network and potentially causing confusion.
    - The trained network can also be used to process entire test images, and the classification scores can be visualized to identify any issues.

The process described above is iterative and may require several rounds of training and validation to achieve a well-performing object detector. The specific training options, such as learning rate and epochs, can be adjusted based on the performance observed during training and validation.