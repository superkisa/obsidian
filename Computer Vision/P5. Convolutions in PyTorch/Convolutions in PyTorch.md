![[sem2_cv_init.ipynb]]

Лажовый [вебинар](https://youtu.be/K2QVHTaAmPc?si=tAXwRJ7JFgy5On-U) от Марата про реализацию сверточных слоев в нумпае и пайторче

#### Convolution NN
![[convolution-operation-on-a-mxnx3-image-matrix-with-a-3x3x3-kernel.gif]]

Сверточные нейронные сети (Convolutional Neural Networks, CNN) - это тип сверточной нейронной сети, который часто используется в компьютерном зрении. CNN используют серию слоев свертки и пулинга для извлечения признаков из изображений и видео, а затем используют эти признаки для классификации или обнаружения объектов или сцен [3](https://www.geeksforgeeks.org/introduction-convolution-neural-network/amp/).

Сверточная нейронная сеть состоит из нескольких слоев, включая входной слой, один или несколько сверточных слоев, пулинговые слои и полносвязные слои. Сверточный слой применяет фильтры к входному изображению для извлечения признаков, пулинговый слой уменьшает размерность изображения для уменьшения вычислительной сложности, а полносвязный слой делает окончательное предсказание [3](https://www.geeksforgeeks.org/introduction-convolution-neural-network/amp/).

В CNN, каждый нейрон в сверточном слое связан только с небольшим регионом входного изображения, называемым его "принимающей областью". Это позволяет сетям обучаться на больших изображениях, используя относительно небольшое количество параметров, что делает их эффективными для обработки изображений [2](https://www.ibm.com/topics/convolutional-neural-networks).

1. **Parameter Sharing**: CNNs use convolutional filters to scan the input image, which greatly reduces the number of parameters, making the network easier to train.
	   Parameter sharing, или обмен параметрами, - это концепция, используемая в сверточных нейронных сетях (CNN), которая позволяет существенно уменьшить количество параметров модели, что делает сеть легче для обучения [5](https://www.geeksforgeeks.org/parameter-sharing-and-typing-in-machine-learning/).
	   
	В обычной полносвязной нейронной сети каждый нейрон в слое связан с каждым входным нейроном, что приводит к большому числу параметров. В сверточных нейронных сетях, однако, каждый нейрон в сверточном слое связан только с небольшой областью входного изображения, называемой его "принимающей областью". Это означает, что каждый нейрон в сверточном слое использует одни и те же параметры (фильтр) для анализа различных областей изображения, что позволяет существенно уменьшить общее число параметров в сети [3](https://ai.stackexchange.com/questions/28320/how-is-parameter-sharing-done-in-cnn).
	
	Благодаря обмену параметров, CNN могут учиться распознавать общие свойства изображений, такие как линии, края и текстуры, независимо от их местоположения на изображении. Это делает CNN очень эффективными для работы с изображениями, поскольку они могут использовать одно и то же представление для различных частей изображения [5](https://www.geeksforgeeks.org/parameter-sharing-and-typing-in-machine-learning/).
	
	Однако стоит отметить, что обмен параметров не всегда является преимуществом. В некоторых случаях, когда конкретные свойства изображения важны для распознавания (например, положение объекта на изображении), обмен параметров может привести к ухудшению производительности модели [3](https://ai.stackexchange.com/questions/28320/how-is-parameter-sharing-done-in-cnn).

2. **Local Connectivity**: Each neuron is connected to only a local region of the input, capturing local patterns effectively.
	Локальная связность в сверточных нейронных сетях (CNN) - это концепция, которая позволяет каждому нейрону быть связанным только с небольшим локальным регионом входного изображения, вместо того, чтобы быть связанным с каждым нейроном в предыдущем слое, как в полносвязных нейронных сетях [1](https://stats.stackexchange.com/questions/159588/how-does-local-connection-implied-in-the-cnn-algorithm).
	
	Это означает, что каждый нейрон в сверточном слое обрабатывает только небольшую часть входного изображения, что позволяет CNN эффективно извлекать локальные признаки из изображения. Например, сверточный слой может обрабатывать только небольшую область изображения, чтобы определить, является ли эта область краем или границей объекта [1](https://stats.stackexchange.com/questions/159588/how-does-local-connection-implied-in-the-cnn-algorithm).
3. **Translation Invariance**: Due to the sliding filter operation, CNNs can detect patterns regardless of their position in the image.
	Translation Invariance, или инвариантность к переносу, - это свойство сверточных нейронных сетей (CNN), которое позволяет им обнаруживать шаблоны независимо от их позиции на изображении. Это достигается благодаря операции сдвига, которую выполняет сверточный слой [1](https://stats.stackexchange.com/questions/208936/what-is-translation-invariance-in-computer-vision-and-convolutional-neural-netwo).
	
	Сверточный слой в CNN применяет фильтры к входному изображению, сдвигая их по всему изображению. Это означает, что каждый фильтр проверяет различные области изображения, что позволяет обнаруживать шаблоны, независимо от их расположения на изображении. Например, если мы ищем красный цвет на изображении, сверточный слой сможет обнаружить красный цвет, независимо от того, находится ли красный цвет в верхнем левом углу, центре или нижнем правом углу изображения [1](https://stats.stackexchange.com/questions/208936/what-is-translation-invariance-in-computer-vision-and-convolutional-neural-netwo).
4. **Hierarchical Feature Learning**: CNNs learn hierarchical features, with lower layers capturing simple patterns and deeper layers capturing more complex patterns.
	Hierarchical Feature Learning, или иерархическое обучение признаков, - это концепция, которая используется в сверточных нейронных сетях (CNN), чтобы улучшить способность сети распознавать сложные шаблоны на изображениях.
	
	В иерархическом обучении признаков, сеть обучается распознавать простые шаблоны на ранних слоях (так называемые "низкоуровневые" слои), а затем использует эти простые шаблоны для распознавания более сложных шаблонов на более глубоких слоях (так называемые "высокоуровневые" слои).
	
	Например, низкоуровневые слои могут быть обучены распознавать простые геометрические формы, такие как линии и края, в то время как более глубокие слои могут быть обучены распознавать более сложные формы, такие как лица или автомобили. Это позволяет сетям обучаться распознавать более сложные объекты, используя простые, уже известные шаблоны [3](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yan_HD-CNN_Hierarchical_Deep_ICCV_2015_paper.pdf).
	
	Иерархическое обучение признаков также позволяет сетям лучше адаптироваться к новым данным. Когда сеть сталкивается с новым объектом, который она ранее не видела, она может использовать свои уже изученные простые шаблоны для начала распознавания этого нового объекта, а затем продолжать обучение на более сложных уровнях для улучшения своего распознавания [5](https://ai.stackexchange.com/questions/31972/when-can-we-call-a-feature-hierarchical).
